# src/agents/coder.py
import json
import yaml
import re
from typing import List, Dict
from pydantic import BaseModel
from src.agents.base import BaseAgent
from src.core.schema import ResearchReport, DesignDocument, FileSpec
from src.utils.logger import sys_logger

class CodeFile(BaseModel):
    filename: str
    content: str

class Codebase(BaseModel):
    files: List[CodeFile]

class CoderAgent(BaseAgent):
    def __init__(self):
        super().__init__(role_name="coder")

    def _get_env_vars(self, env_config: dict) -> dict:
        return {
            "os_platform": env_config.get("os_platform", "linux"),
            "hardware_context": env_config.get("experience_context", env_config.get("hardware_context", "CPU"))
        }

    # [ä¿®æ”¹] æ™ºèƒ½éª¨æž¶ç”Ÿæˆæ–¹æ³•
    def write_smart_skeleton(self, 
                             file_spec: FileSpec, 
                             design: DesignDocument, 
                             research: ResearchReport, 
                             env_config: dict) -> CodeFile:
        
        sys_logger.info(f"ðŸ§± Smart Scaffolding: {file_spec.filename}...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["smart_skeleton_template"]
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        spec_json = file_spec.model_dump_json(indent=2)
        design_summary = f"Style: {design.architecture_style}\nFlow: {design.main_execution_flow}"
        
        # è°ƒç”¨ LLMï¼ŒæœŸæœ›è¿”å›ž Codebase ç»“æž„
        result = self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase, 
            filename=file_spec.filename,
            file_spec_json=spec_json,
            idea=research.refined_idea,
            design_context=design_summary,
            **self._get_env_vars(env_config)
        )
        
        # æå–ç»“æžœ
        target_name = file_spec.filename
        for f in result.files:
            # æ¨¡ç³ŠåŒ¹é…æ–‡ä»¶åï¼Œé˜²æ­¢ LLM æ”¹åæˆ–åŽ»æŽ‰è·¯å¾„
            if f.filename.endswith(target_name) or target_name.endswith(f.filename):
                # å¼ºåˆ¶ä¿®æ­£ä¸º Spec ä¸­çš„æ ‡å‡†æ–‡ä»¶åï¼Œé˜²æ­¢è·¯å¾„æ··ä¹±
                f.filename = target_name 
                return f
        
        # å…œåº•ï¼šå¦‚æžœ LLM è¿”å›žäº†æ–‡ä»¶ä½†åå­—å¯¹ä¸ä¸Šï¼Œé»˜è®¤å–ç¬¬ä¸€ä¸ª
        if result.files:
            f = result.files[0]
            f.filename = target_name
            return f
            
        return CodeFile(filename=target_name, content=f"# Generation Failed for {target_name}")

    def generate_env_yaml(self, design: DesignDocument, env_config: dict) -> Codebase:
        """åªç”Ÿæˆ environment.yaml"""
        sys_logger.info("Coder: Generating environment configuration...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["env_gen_template"]
        
        reqs_str = "\n".join(design.requirements)
        design_str = design.model_dump_json(indent=2)
        
        codebase = self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase,
            requirements=reqs_str,
            design_doc=design_str,
            **self._get_env_vars(env_config)
        )
        
        self._inject_requirements(codebase, env_config)
        return codebase

    # [ä¿®æ”¹] ä¿®å¤ filename å˜é‡ä½œç”¨åŸŸé”™è¯¯
    def implement_single_file(self, 
                              file_spec: FileSpec, 
                              current_skeleton: str, 
                              project_context: str, 
                              env_config: dict) -> CodeFile:
        
        sys_logger.info(f"âœï¸ Coder: Implementing {file_spec.filename}...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["implement_template"]
        
        spec_json = file_spec.model_dump_json(indent=2)
        
        result = self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase,
            filename=file_spec.filename,
            file_spec_json=spec_json,
            current_skeleton=current_skeleton,
            project_context=project_context,
            **self._get_env_vars(env_config)
        )
        
        target_name = file_spec.filename
        for f in result.files:
            # æ¨¡ç³ŠåŒ¹é…
            if f.filename.endswith(target_name) or target_name.endswith(f.filename):
                f.filename = target_name # å¼ºåˆ¶ä¿®æ­£
                return f
        
        # å…œåº•
        if result.files:
            f = result.files[0]
            f.filename = target_name
            return f
            
        return CodeFile(filename=target_name, content=current_skeleton)

    def fix_code(self, command: str, error_log: str, files: Dict[str, str], env_config: dict) -> Codebase:
        sys_logger.info("ðŸš‘ Coder: Analyzing error and fixing code...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["fix_bug_template"]
        
        code_context = ""
        for name, content in files.items():
            content_trunc = content if len(content) < 3000 else content[:1500] + "\n...[truncated]...\n" + content[-1500:]
            code_context += f"--- FILE: {name} ---\n{content_trunc}\n\n"

        return self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase,
            command=command,
            error_log=error_log[-5000:],
            file_content=code_context,
            **self._get_env_vars(env_config)
        )

    def _inject_requirements(self, codebase: Codebase, env_config: dict):
        """è§£æž config ç»“æž„åŒ–ä¾èµ–å¹¶æ³¨å…¥ environment.yaml"""
        base_reqs = env_config.get("base_requirements", {})
        python_ver = env_config.get("python_version", "3.11")
        
        config_conda_pkgs = base_reqs.get("conda", [])
        config_pip_pkgs = base_reqs.get("pip", [])

        # Pip é»‘åå•
        pip_blacklist = set()
        for item in config_pip_pkgs:
            item_str = str(item).strip()
            if item_str.startswith("-"): continue
            pkg_name = re.split(r'[<>=!]', item_str)[0].strip()
            pip_blacklist.add(pkg_name)
            if pkg_name == "torch":
                pip_blacklist.add("pytorch")
                pip_blacklist.add("pytorch-cuda")

        # æ‰¾åˆ° environment.yaml
        yaml_file = next((f for f in codebase.files if "environment.yaml" in f.filename or "environment.yml" in f.filename), None)
        if not yaml_file:
            yaml_file = CodeFile(filename="environment.yaml", content="name: project_env\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n")
            codebase.files.append(yaml_file)

        try:
            env_data = yaml.safe_load(yaml_file.content) or {}
            
            if "channels" not in env_data:
                env_data["channels"] = ["conda-forge", "defaults"]
            else:
                if "conda-forge" not in env_data["channels"]:
                    env_data["channels"].insert(0, "conda-forge")
            
            if "dependencies" not in env_data:
                env_data["dependencies"] = []
            
            original_deps = env_data["dependencies"]
            
            new_deps = []
            new_deps.append(f"python={python_ver}")
            new_deps.append("pip")

            for pkg in config_conda_pkgs:
                if pkg not in new_deps:
                    new_deps.append(pkg)
            
            for item in original_deps:
                if isinstance(item, str):
                    if item.startswith("python=") or item == "pip":
                        continue
                    llm_pkg_name = re.split(r'[<>=!]', item)[0].strip()
                    if llm_pkg_name in pip_blacklist:
                        continue
                    if item not in new_deps:
                        new_deps.append(item)
            
            llm_pip_list = []
            for item in original_deps:
                if isinstance(item, dict) and "pip" in item:
                    llm_pip_list.extend(item["pip"])
            
            final_pip_list = []
            index_url_line = None
            
            for pkg in config_pip_pkgs:
                pkg_str = str(pkg).strip()
                if "--index-url" in pkg_str:
                    index_url_line = pkg_str
                else:
                    if pkg_str not in final_pip_list:
                        final_pip_list.append(pkg_str)
            
            for pkg in llm_pip_list:
                pkg_str = str(pkg).strip()
                if "--index-url" in pkg_str: continue 
                
                pkg_name = re.split(r'[<>=!]', pkg_str)[0].strip()
                is_duplicate = False
                for existing in final_pip_list:
                    existing_name = re.split(r'[<>=!]', existing)[0].strip()
                    if pkg_name == existing_name:
                        is_duplicate = True
                        break
                if not is_duplicate:
                    final_pip_list.append(pkg_str)

            if final_pip_list or index_url_line:
                pip_block = []
                if index_url_line:
                    pip_block.append(index_url_line)
                pip_block.extend(final_pip_list)
                new_deps.append({"pip": pip_block})

            env_data["dependencies"] = new_deps
            yaml_file.content = yaml.dump(env_data, sort_keys=False, default_flow_style=False)
            sys_logger.info("âœ… Successfully injected and sanitized requirements.")

        except Exception as e:
            sys_logger.error(f"Failed to inject requirements: {e}")