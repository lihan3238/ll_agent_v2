# src/agents/coder.py
import json
import yaml
import re
from typing import List, Dict
from pydantic import BaseModel
from src.agents.base import BaseAgent
from src.core.schema import ResearchReport,DesignDocument, FileSpec
from src.utils.logger import sys_logger

class CodeFile(BaseModel):
    filename: str
    content: str

class Codebase(BaseModel):
    files: List[CodeFile]

class CoderAgent(BaseAgent):
    def __init__(self):
        super().__init__(role_name="coder")

    def _get_env_vars(self, env_config: dict) -> dict:
        return {
            "os_platform": env_config.get("os_platform", "linux"),
            "hardware_context": env_config.get("experience_context", env_config.get("hardware_context", "CPU"))
        }

    # [æ–°å¢] æ™ºèƒ½éª¨æ¶ç”Ÿæˆæ–¹æ³•
    def write_smart_skeleton(self, 
                             file_spec: FileSpec, 
                             design: DesignDocument, 
                             research: ResearchReport, 
                             env_config: dict) -> CodeFile:
        
        sys_logger.info(f"ğŸ§± Smart Scaffolding: {file_spec.filename}...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["smart_skeleton_template"]
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        spec_json = file_spec.model_dump_json(indent=2)
        # æå– Architect çš„å…³é”®ä¿¡æ¯ (é˜²æ­¢ token çˆ†ç‚¸ï¼Œä¸ä¼ æ•´ä¸ª design)
        design_summary = f"Style: {design.architecture_style}\nFlow: {design.main_execution_flow}"
        
        # è°ƒç”¨ LLM ç”Ÿæˆå•ä¸ªæ–‡ä»¶çš„éª¨æ¶ä»£ç 
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è®© LLM ç›´æ¥è¿”å› CodeFile ç»“æ„
        # æˆ–è€…ä¸ºäº†ç®€å•ï¼Œå¦‚æœæ¨¡æ¿è¿”å›çš„æ˜¯çº¯ä»£ç ï¼Œæˆ‘ä»¬éœ€è¦åŒ…è£…ä¸€ä¸‹
        # ä¸ºäº†å¤ç”¨ call_llm_with_structï¼Œæˆ‘ä»¬è®©å®ƒè¿”å› CodeFile
        
        # è¿™é‡Œéœ€è¦ç¨å¾® trick ä¸€ä¸‹ï¼Œå› ä¸º smart_skeleton_template æœŸæœ›è¿”å›ä»£ç 
        # ä½†æˆ‘ä»¬çš„ base agent æœŸæœ› JSONã€‚
        # å»ºè®®ï¼šä¿®æ”¹ prompt è®©å®ƒè¿”å› JSON åŒ…å« {filename, content}
        # æˆ–è€…ï¼šæˆ‘ä»¬è¿™é‡Œæ‰‹åŠ¨æ„é€  CodeFile
        
        # è®©æˆ‘ä»¬å¤ç”¨ call_llm_with_struct, è®© prompt æŒ‡ç¤ºè¿”å› JSON
        # æ­¤æ—¶ prompt é‡Œçš„ Target Schema ä¼šç”Ÿæ•ˆ
        
        result = self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase, # å¤ç”¨ Codebase ç»“æ„ (è™½ç„¶åªè¿”å›ä¸€ä¸ªæ–‡ä»¶)
            filename=file_spec.filename,
            file_spec_json=spec_json,
            idea=research.refined_idea,
            design_context=design_summary,
            **self._get_env_vars(env_config)
        )
        
        # æå–ç»“æœ
        for f in result.files:
            # æ¨¡ç³ŠåŒ¹é…æ–‡ä»¶åï¼Œé˜²æ­¢ LLM æ”¹å
            if file_spec.filename in f.filename or f.filename in file_spec.filename:
                return f
        
        # å…œåº•
        return result.files[0] if result.files else CodeFile(filename=file_spec.filename, content="# Generation Failed")

    def generate_env_yaml(self, design: DesignDocument, env_config: dict) -> Codebase:
        """åªç”Ÿæˆ environment.yaml"""
        sys_logger.info("Coder: Generating environment configuration...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["env_gen_template"]
        
        # å‡†å¤‡ Requirements å­—ç¬¦ä¸²
        reqs_str = "\n".join(design.requirements)
        
        # åºåˆ—åŒ– Design Doc (é˜²å¾¡æ€§æªæ–½ï¼šå³ä½¿æ¨¡æ¿é‡Œè¯¯å†™äº† {design_doc}ï¼Œä¼ è¿›å»ä¹Ÿä¸ä¼šæŠ¥é”™)
        design_str = design.model_dump_json(indent=2)
        
        codebase = self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase,
            requirements=reqs_str,
            design_doc=design_str, # [æ–°å¢] ä¼ å…¥æ­¤å˜é‡ä»¥é˜²æ¨¡æ¿éœ€è¦
            **self._get_env_vars(env_config)
        )
        
        # æ³¨å…¥ä¾èµ– [ä¹‹å‰æŠ¥é”™å°±æ˜¯å› ä¸ºä¸‹é¢è¿™ä¸ªæ–¹æ³•æ²¡å®šä¹‰]
        self._inject_requirements(codebase, env_config)
        return codebase

    def implement_single_file(self, 
                              file_spec: FileSpec, 
                              current_skeleton: str, 
                              project_context: str, 
                              env_config: dict) -> CodeFile:
        
        sys_logger.info(f"âœï¸ Coder: Implementing {file_spec.filename}...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["implement_template"]
        
        spec_json = file_spec.model_dump_json(indent=2)
        
        result = self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase,
            filename=file_spec.filename,
            file_spec_json=spec_json,
            current_skeleton=current_skeleton,
            project_context=project_context,
            **self._get_env_vars(env_config)
        )
        
        for f in result.files:
            if f.filename == filename or filename in f.filename: # ç®€å•æ¨¡ç³ŠåŒ¹é…
                return f
        return result.files[0] if result.files else CodeFile(filename=file_spec.filename, content=current_skeleton)

    def fix_code(self, command: str, error_log: str, files: Dict[str, str], env_config: dict) -> Codebase:
        sys_logger.info("ğŸš‘ Coder: Analyzing error and fixing code...")
        
        full_prompt = self.prompts["system"] + "\n\n" + self.prompts["fix_bug_template"]
        
        code_context = ""
        for name, content in files.items():
            content_trunc = content if len(content) < 3000 else content[:1500] + "\n...[truncated]...\n" + content[-1500:]
            code_context += f"--- FILE: {name} ---\n{content_trunc}\n\n"

        return self.call_llm_with_struct(
            prompt_template=full_prompt,
            schema=Codebase,
            command=command,
            error_log=error_log[-5000:],
            file_content=code_context,
            **self._get_env_vars(env_config)
        )

    def _inject_requirements(self, codebase: Codebase, env_config: dict):
        """
        [è¡¥å…¨çš„æ–¹æ³•] è§£æ config ç»“æ„åŒ–ä¾èµ–å¹¶æ³¨å…¥ environment.yaml
        """
        base_reqs = env_config.get("base_requirements", {})
        python_ver = env_config.get("python_version", "3.11")
        
        config_conda_pkgs = base_reqs.get("conda", [])
        config_pip_pkgs = base_reqs.get("pip", [])

        # 1. å»ºç«‹ Pip é»‘åå•
        pip_blacklist = set()
        for item in config_pip_pkgs:
            item_str = str(item).strip()
            if item_str.startswith("-"): continue
            pkg_name = re.split(r'[<>=!]', item_str)[0].strip()
            pip_blacklist.add(pkg_name)
            if pkg_name == "torch":
                pip_blacklist.add("pytorch")
                pip_blacklist.add("pytorch-cuda")

        # 2. æ‰¾åˆ°/åˆ›å»º environment.yaml
        yaml_file = next((f for f in codebase.files if "environment.yaml" in f.filename or "environment.yml" in f.filename), None)
        if not yaml_file:
            # [ä¿®æ”¹] é»˜è®¤åŠ å…¥ conda-forge
            yaml_file = CodeFile(filename="environment.yaml", content="name: project_env\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n")
            codebase.files.append(yaml_file)

        try:
            env_data = yaml.safe_load(yaml_file.content) or {}
            
            # [æ–°å¢] å¼ºåˆ¶ç¡®ä¿ conda-forge å­˜åœ¨ä¸”ä¼˜å…ˆçº§æœ€é«˜
            if "channels" not in env_data:
                env_data["channels"] = ["conda-forge", "defaults"]
            else:
                if "conda-forge" not in env_data["channels"]:
                    env_data["channels"].insert(0, "conda-forge")
            
            if "dependencies" not in env_data:
                env_data["dependencies"] = []
            
            original_deps = env_data["dependencies"]
            
            # --- æ„å»ºæ–°çš„ dependencies åˆ—è¡¨ ---
            new_deps = []
            
            # A. å¼ºåˆ¶ Python ç‰ˆæœ¬
            new_deps.append(f"python={python_ver}")
            new_deps.append("pip")

            # B. æ³¨å…¥ Config ä¸­çš„ Conda åŒ…
            for pkg in config_conda_pkgs:
                if pkg not in new_deps:
                    new_deps.append(pkg)
            
            # C. ç­›é€‰ LLM ç”Ÿæˆçš„ Conda åŒ…
            for item in original_deps:
                if isinstance(item, str):
                    if item.startswith("python=") or item == "pip":
                        continue
                    
                    llm_pkg_name = re.split(r'[<>=!]', item)[0].strip()
                    
                    if llm_pkg_name in pip_blacklist:
                        sys_logger.warning(f"ğŸš« Removing '{item}' from Conda list because it is defined in Pip config.")
                        continue
                        
                    if item not in new_deps:
                        new_deps.append(item)
            
            # D. å¤„ç† Pip åŒ…
            llm_pip_list = []
            for item in original_deps:
                if isinstance(item, dict) and "pip" in item:
                    llm_pip_list.extend(item["pip"])
            
            final_pip_list = []
            index_url_line = None
            
            # D1. Config Pip
            for pkg in config_pip_pkgs:
                pkg_str = str(pkg).strip()
                if "--index-url" in pkg_str:
                    index_url_line = pkg_str
                else:
                    if pkg_str not in final_pip_list:
                        final_pip_list.append(pkg_str)
            
            # D2. LLM Pip (å»é‡)
            for pkg in llm_pip_list:
                pkg_str = str(pkg).strip()
                if "--index-url" in pkg_str: continue 
                
                pkg_name = re.split(r'[<>=!]', pkg_str)[0].strip()
                is_duplicate = False
                for existing in final_pip_list:
                    existing_name = re.split(r'[<>=!]', existing)[0].strip()
                    if pkg_name == existing_name:
                        is_duplicate = True
                        break
                
                if not is_duplicate:
                    final_pip_list.append(pkg_str)

            # E. ç»„è£…
            if final_pip_list or index_url_line:
                pip_block = []
                if index_url_line:
                    pip_block.append(index_url_line)
                pip_block.extend(final_pip_list)
                new_deps.append({"pip": pip_block})

            # F. å†™å›
            env_data["dependencies"] = new_deps
            yaml_file.content = yaml.dump(env_data, sort_keys=False, default_flow_style=False)
            sys_logger.info("âœ… Successfully injected and sanitized requirements.")

        except Exception as e:
            sys_logger.error(f"Failed to inject requirements: {e}")