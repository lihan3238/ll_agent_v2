# üìù Èò∂ÊÆµÂÆ°Êü•: 01_Research_Round_2

## 1. Ê†∏ÂøÉÊÄùË∑Ø (Refined Idea)
> **This research proposes a non-stationary selective state space architecture for multivariate time series forecasting that fundamentally addresses the linear time-invariant (LTI) constraint in standard Mamba models. The framework integrates learnable temporal routing mechanisms with multi-scale decomposition, where explicit stationarization modules model time-varying statistical properties through adaptive parameterization of state transition matrices. A differentiable gating mechanism dynamically routes temporal patterns to specialized state space experts based on spectral characteristics, overcoming static expert allocation in existing hybrid approaches. Theoretical analysis demonstrates this time-varying formulation can approximate a strictly larger class of dynamical systems than LTI state space models while maintaining computational efficiency through selective scanning mechanisms.**

## 2. ÊêúÁ¥¢ÂÖ≥ÈîÆËØç (Keywords)
- `non-stationary state space models`
- `time-varying parameterization`
- `multivariate time series forecasting`
- `adaptive temporal routing`
- `selective state space experts`
- `spectral pattern decomposition`
- `differentiable gating mechanisms`

## 3. Áõ∏ÂÖ≥Â∑•‰ΩúÁªºËø∞ (Related Work)
Current state space models for time series forecasting, particularly the Mamba architecture and its derivatives, operate under the fundamental constraint of linear time-invariant (LTI) systems. While STG-Mamba demonstrates the application of selective state space models to spatial-temporal graph data, it inherits the LTI limitation that assumes stationary temporal dynamics. This assumption is fundamentally violated in real-world time series exhibiting time-varying statistical properties, non-stationary patterns, and regime changes. Transformer-based approaches, while powerful for capturing dependencies, suffer from quadratic computational complexity and lack the efficient long-range modeling capabilities of state space approaches. The critical gap lies in the mathematical formulation itself: existing state space models parameterize their transition matrices as static components, unable to adapt to the time-varying nature of real-world processes. This limitation becomes particularly acute in multivariate forecasting where different temporal components may exhibit varying degrees of stationarity and require specialized modeling approaches. The proposed non-stationary formulation addresses this core mathematical limitation by introducing time-adaptive parameterization and dynamic routing mechanisms.

## 4. ÈáçÁÇπËÆ∫Êñá (Top Papers)
| Year | Citations | Title |
| :---: | :---: | --- |
| 2023 | 207 | [A Review of ARIMA vs. Machine Learning Approaches for Time Series Forecasting in Data Driven Networks](https://www.semanticscholar.org/paper/1f1899907a1121e9c224a0cd01676e8ac7c03ff2) |
| 2024 | 161 | [Is Mamba Effective for Time Series Forecasting?](https://www.semanticscholar.org/paper/dba88f9a59ad816ce14d93b2c8bfda5917adc196) |
| 2023 | 73 | [Expectation‚Äêmaximization algorithm for bilinear state‚Äêspace models with time‚Äêvarying delays under non‚ÄêGaussian noise](https://www.semanticscholar.org/paper/15a6b937eafeca7586ddaf1b3eab34c45b238358) |
| 2024 | 27 | [SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video Grounding](https://www.semanticscholar.org/paper/bb6afe666ffd07d9059ec94cac551c2b1f33f096) |
| 2024 | 26 | [STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model](https://www.semanticscholar.org/paper/46f33203f6f50bbd38d2e3e3eb1aa4f3eb66715d) |

### ËÆ∫ÊñáÊëòË¶ÅËØ¶ÊÉÖ:
- **A Review of ARIMA vs. Machine Learning Approaches for Time Series Forecasting in Data Driven Networks**
  - *Summary*: In the broad scientific field of time series forecasting, the ARIMA models and their variants have been widely applied for half a century now due to their mathematical simplicity and flexibility in application. However, with the recent advances in the development and efficient deployment of artificial intelligence models and techniques, the view is rapidly changing, with a shift towards machine and deep learning approaches becoming apparent, even without a complete evaluation of the superiority of the new approach over the classic statistical algorithms. Our work constitutes an extensive review of the published scientific literature regarding the comparison of ARIMA and machine learning algorithms applied to time series forecasting problems, as well as the combination of these two approaches in hybrid statistical-AI models in a wide variety of data applications (finance, health, weather, utilities, and network traffic prediction). Our review has shown that the AI algorithms display better prediction performance in most applications, with a few notable exceptions analyzed in our Discussion and Conclusions sections, while the hybrid statistical-AI models steadily outperform their individual parts, utilizing the best algorithmic features of both worlds.
- **Is Mamba Effective for Time Series Forecasting?**
  - *Summary*: In the realm of time series forecasting (TSF), it is imperative for models to adeptly discern and distill hidden patterns within historical time series data to forecast future states. Transformer-based models exhibit formidable efficacy in TSF, primarily attributed to their advantage in apprehending these patterns. However, the quadratic complexity of the Transformer leads to low computational efficiency and high costs, which somewhat hinders the deployment of the TSF model in real-world scenarios. Recently, Mamba, a selective state space model, has gained traction due to its ability to process dependencies in sequences while maintaining near-linear complexity. For TSF tasks, these characteristics enable Mamba to comprehend hidden patterns as the Transformer and reduce computational overhead compared to the Transformer. Therefore, we propose a Mamba-based model named Simple-Mamba (S-Mamba) for TSF. Specifically, we tokenize the time points of each variate autonomously via a linear layer. A bidirectional Mamba layer is utilized to extract inter-variate correlations and a Feed-Forward Network is set to learn temporal dependencies. Finally, the generation of forecast outcomes through a linear mapping layer. Experiments on thirteen public datasets prove that S-Mamba maintains low computational overhead and achieves leading performance. Furthermore, we conduct extensive experiments to explore Mamba's potential in TSF tasks. Our code is available at https://github.com/wzhwzhwzh0921/S-D-Mamba.
- **Expectation‚Äêmaximization algorithm for bilinear state‚Äêspace models with time‚Äêvarying delays under non‚ÄêGaussian noise**
  - *Summary*: In this paper, the parameter identification of bilinear state‚Äêspace model (SSM) in the presence of random outliers and time‚Äêvarying delays is investigated. Under the basis of the observable canonical form of the bilinear model, the system output can be written as a regressive form, and a bilinear state observer is applied to estimate the unknown states. To eliminate the influence of outliers and time‚Äêvarying delays on parameter estimation, we employ the Student's t$$ t $$ distribution to deal with the measurement noise and use a first‚Äêorder Markov chain to model the delays. In the framework of expectation‚Äêmaximization (EM) algorithm, the unknown parameters, delays, noise variance, states and transition probability matrix can be estimated iteratively. A numerical simulation and a continuous stirred tank reactor (CSTR) process demonstrate that the proposed algorithm has good immunity against outliers and time‚Äêvarying delays and offers good estimation accuracy for the bilinear SSM.
- **SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video Grounding**
  - *Summary*: Temporal video grounding (TVG) is a critical task in video content understanding, requiring precise alignment between video content and natural language instructions. Despite significant advancements, existing methods face challenges in managing confidence bias towards salient objects and capturing long-term dependencies in video sequences. To address these issues, we introduce SpikeMba: a multi-modal spiking saliency mamba for temporal video grounding. Our approach integrates Spiking Neural Networks (SNNs) with state space models (SSMs) to leverage their unique advantages in handling different aspects of the task. Specifically, we use SNNs to develop a spiking saliency detector that generates the proposal set. The detector emits spike signals when the input signal exceeds a predefined threshold, resulting in a dynamic and binary saliency proposal set. To enhance the model's capability to retain and infer contextual information, we introduce relevant slots which learnable tensors that encode prior knowledge. These slots work with the contextual moment reasoner to maintain a balance between preserving contextual information and exploring semantic relevance dynamically. The SSMs facilitate selective information propagation, addressing the challenge of long-term dependency in video content. By combining SNNs for proposal generation and SSMs for effective contextual reasoning, SpikeMba addresses confidence bias and long-term dependencies, thereby significantly enhancing fine-grained multimodal relationship capture. Our experiments demonstrate the effectiveness of SpikeMba, which consistently outperforms state-of-the-art methods across mainstream benchmarks.
- **STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model**
  - *Summary*: Spatial-Temporal Graph (STG) data is characterized as dynamic, heterogenous, and non-stationary, leading to the continuous challenge of spatial-temporal graph learning. In the past few years, various GNN-based methods have been proposed to solely focus on mimicking the relationships among node individuals of the STG network, ignoring the significance of modeling the intrinsic features that exist in STG system over time. In contrast, modern Selective State Space Models (SSSMs) present a new approach which treat STG Network as a system, and meticulously explore the STG system's dynamic state evolution across temporal dimension. In this work, we introduce Spatial-Temporal Graph Mamba (STG-Mamba) as the first exploration of leveraging the powerful selective state space models for STG learning by treating STG Network as a system, and employing the Spatial-Temporal Selective State Space Module (ST-S3M) to precisely focus on the selected STG latent features. Furthermore, to strengthen GNN's ability of modeling STG data under the setting of selective state space models, we propose Kalman Filtering Graph Neural Networks (KFGN) for dynamically integrate and upgrade the STG embeddings from different temporal granularities through a learnable Kalman Filtering statistical theory-based approach. Extensive empirical studies are conducted on three benchmark STG forecasting datasets, demonstrating the performance superiority and computational efficiency of STG-Mamba. It not only surpasses existing state-of-the-art methods in terms of STG forecasting performance, but also effectively alleviate the computational bottleneck of large-scale graph networks in reducing the computational cost of FLOPs and test inference time. The implementation code is available at: \url{https://github.com/LincanLi98/STG-Mamba}.

## 5. ÂÆûÊñΩÂª∫ËÆÆ (Implementation Suggestions)
Implement a multi-stage architecture beginning with multi-scale decomposition using wavelet transforms or learned convolutional filters to separate temporal components. Design time-varying state transition matrices parameterized by learned functions of time or input-dependent modulation. Develop a differentiable gating network that routes temporal segments to specialized state space experts based on spectral characteristics (e.g., frequency content, stationarity measures). Conduct ablation studies comparing: (1) fixed vs. adaptive parameterization of state matrices, (2) static vs. dynamic expert routing, (3) different stationarization techniques (differencing, normalization, transformation), and (4) various gating mechanisms (softmax, sparsemax, top-k). Validate on datasets with known non-stationary properties and regime changes to demonstrate superior performance over LTI baselines.

---
<!-- ‚ö†Ô∏è Á≥ªÁªüÂàÜÂâ≤Á∫ø (SYSTEM SEPARATOR) - ËØ∑ÂãøÂà†Èô§Êàñ‰øÆÊîπÊ≠§Ë°å‰ª•‰∏äÂÜÖÂÆπ -->

# üü¢ Áî®Êà∑ÂÜ≥Á≠ñÂå∫ (User Decision)

ËØ∑Âú®‰∏ãÊñπÂ°´ÂÜôÊÇ®ÁöÑÂÜ≥ÂÆö„ÄÇ**ÊîØÊåÅ‰∏≠Êñá**ÔºåÁ≥ªÁªü‰ºöËá™Âä®ÁøªËØë„ÄÇ

**ÂÜ≥Á≠ñ (Action)**: [ APPROVE ] 
<!-- ÈÄâÈ°π: APPROVE (ÈÄöËøá), REVISE (‰øÆÊîπ) -->

**ÂèçÈ¶àÊÑèËßÅ (Feedback)**:
<!-- Â¶ÇÊûúÈÄâÊã© REVISEÔºåËØ∑Â°´ÂÜôÂÖ∑‰Ωì‰øÆÊîπÊÑèËßÅ„ÄÇ‰æãÂ¶ÇÔºö"ËØ∑Â¢ûÂä†ÂØπÊØîÂÆûÈ™å..." -->